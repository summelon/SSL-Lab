_target_: pytorch_lightning.Trainer
gpus: ${basic.num_gpus}
max_epochs: ???
sync_batchnorm: ???
accumulate_grad_batches: ???
resume_from_checkpoint: ${basic.resume}
distributed_backend: "ddp"
default_root_dir: ${basic.ckpt_base_dir}
precision: 32
