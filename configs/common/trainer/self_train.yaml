# @package _global_
defaults:
  - default@trainer
  - override /callbacks@_global_: self_train
  - override /optimizer@model: self_train

basic:
  stage: self_train
  model_class: arch.modules.self_train.SelfTrainModel

trainer:
  max_epochs: 400

model:
  basic:
    # Linear_eval case
    ckpt_path: ${basic.pretrained}
    # Alpha = 1: using kd_loss only
    alpha: 1.0
    # Self distillation: 0.1
    # Large -> small: 1.0
    temperature: 0.1
    student_size: same
  mlp: null

transform:
  train_transforms:
    supervised: True
